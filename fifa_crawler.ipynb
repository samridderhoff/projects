{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc621dc",
   "metadata": {},
   "source": [
    "This is a python crawler that scrapes data about the Fifa 22 transfer market. All data is scraped from https://www.futwiz.com/en/fifa22/players. Data are intitially obtained using the requets module, the formatted using BeautifulSoup from the bs4 module, and then transformed to a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3efc54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c89ae42",
   "metadata": {},
   "source": [
    "After experimentation with reading in the data, there were a few points found in the data that need to be cleaned. The first comes with dealing with names. The player's names are scraped by the name that appears on their jersey in real life, as that is how their cards appear in Fifa. Due to the nature of the site, functions are needed to deal with special characters (ü, é, etc.) in the html representation of the player's names. Also, a player whose name contain a space can also be cleaned (i.e. Wissam, Ben Yedder is read in as Yedder before a function is called). Functions to deal with these cases are defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07bec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names(string):\n",
    "    \"\"\"\n",
    "   A function that will return the cleaned player's name\n",
    "   \n",
    "   Parameters\n",
    "   ----------\n",
    "   string:\n",
    "       the intitial player's name\n",
    "   -------\n",
    "   Returns the player's cleaned name.\n",
    "   \"\"\"\n",
    "    return string.replace(' ', '').replace(\"Ã©\",\"é\").replace('Ã¡','á').replace('Ã¼','ü').replace('Ã±', 'ñ').replace('Ãº','ú').replace('Ä\\x87','ć').replace('Ã¤','ä').replace('Ã\\xad','í').replace('Ã³','ó').replace('Ä\\x8c','Č').replace('Ä\\x9b','ě').replace('Ã¨','è').replace('Ã¶','ö').replace('Ã§','ç').replace('Å\\xa0','Š').replace('Ä\\x8d','ć').replace('Ã\\x81','Á').replace('Ã\\x96','Ö').replace('Ã¦','ae').replace('Ä\\x9f','ğ').replace('Ä±','i').replace('Å\\x84','ń').replace('Å»','Ż').replace('Å\\x9f','ş').replace('Ã\\x98','Ø').replace('Ã«','ë').replace('Ã£','ã').replace('Ã¯','ï').replace('Ã\\x87','Ç').replace('Å¾','ž')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ebfb824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_names(string,pageNo):\n",
    "    \"\"\"\n",
    "   A function that will change the player's name to deal with spaces\n",
    "   \n",
    "   Parameters\n",
    "   ----------\n",
    "   string:\n",
    "       the intitial player's name\n",
    "   pageNo:\n",
    "       an upper bound on the site page to include the name\n",
    "   -------\n",
    "   Returns the player's cleaned name.\n",
    "   \"\"\"\n",
    "    #Check if the name matches any of the following\n",
    "    if(string=='Gea'):\n",
    "        #If yes then return the corrected name\n",
    "        return 'De Gea'\n",
    "    if((string=='Jr') & (pageNo<=100)):\n",
    "        return 'Neymar'\n",
    "    if(string=='Dijk'):\n",
    "        return 'Van Dijk'\n",
    "    if(string=='Bruyne'):\n",
    "        return 'De Bruyne'\n",
    "    if(string=='Yedder'):\n",
    "        return 'Ben Yedder'\n",
    "    if((string=='Dias') & (pageNo<=100)):\n",
    "        return 'Ruben Dias'\n",
    "    if(string=='Basten'):\n",
    "        return 'Van Basten'\n",
    "    if(string=='Nistelrooy'):\n",
    "        return 'Van Nistelrooy'\n",
    "    if(string=='Piero'):\n",
    "        return 'Del Piero'\n",
    "    if(string=='Stegen'):\n",
    "        return 'Ter Stegen'\n",
    "    if(string=='Persie'):\n",
    "        return 'Van Persie'\n",
    "    if((string=='Tomás')& (pageNo<=165)):\n",
    "        return 'De Tomás'\n",
    "    if(string=='Dasari'):\n",
    "        return 'Al Dasari'\n",
    "    if(string=='Vrij'):\n",
    "        return 'De Vrij'\n",
    "    if((string=='Beek') & (pageNo <= 165)):\n",
    "        return 'Van De Beek'\n",
    "    if((string=='Jong') & (pageNo <= 165)):\n",
    "        return 'De Jong'\n",
    "    if(string=='Lorenzo'):\n",
    "        return 'De Lorenzo'\n",
    "    if(string=='Ligt'):\n",
    "        return 'De Ligt'\n",
    "    if((string=='Paul') & (pageNo <= 165)):\n",
    "        return 'De Paul'\n",
    "    if(string=='María'):\n",
    "        return 'De María'\n",
    "    else:\n",
    "        return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcd8be9",
   "metadata": {},
   "source": [
    "The next step of cleaning is dealing with the Price column. Some players do not have prices on the market, but are included in the players database. This can be for a number reasons; the most common being that the player can be earned but not purchased. Also, the way that Futwiz displays their prices is not practical for testing our data. For example, a price of 4,400 is stored as 4.4k, which can cause issues with handling numbers as strings. What we want is to deal with prices as ints (ex. 4.4k as 4400). The function to take care of these scenarios is defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "396cbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(price):\n",
    "    \"\"\"\n",
    "   A function that will return the cleaned player's price\n",
    "   \n",
    "   Parameters\n",
    "   ----------\n",
    "   price:\n",
    "       the intitial player's price\n",
    "   -------\n",
    "   Returns the player's cleaned price.\n",
    "   \"\"\"\n",
    "    #First override price to deal with the nuisance of the way the price is scraped\n",
    "    price = price.replace('\\n', \"\").replace(\" \",\"\")\n",
    "    #When the player does not have a price on the market, the player will be given a market value of 0.\n",
    "    if(price==''):\n",
    "        return 0\n",
    "    #Next check if the player is priced in the millions.\n",
    "    elif 'M' in price:\n",
    "        #If yes, override and return an int casting of the player's price.\n",
    "        price = price.replace('M','')\n",
    "        price = float(price)\n",
    "        price = price * 1000000\n",
    "        return int(price)\n",
    "    #Next check if the player is priced in the thousands.\n",
    "    elif 'K' in price:\n",
    "        #If yes, override and return an int casting of the player's price.\n",
    "        price = price.replace('K','')\n",
    "        price = float(price)\n",
    "        price = price * 1000\n",
    "        return int(price)\n",
    "    else:\n",
    "        #If the player does not meet any of these special cases, return the price casted as an int\n",
    "        return int(price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78e54d",
   "metadata": {},
   "source": [
    "Now that the data has been cleaned, we will define a function that will scrape Futwiz and give us a dataframe that we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0dd042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(pageNo):\n",
    "    \"\"\"\n",
    "   A function that scrapes a given page on Futwiz and gives us data to work with\n",
    "   \n",
    "   Parameters\n",
    "   ----------\n",
    "   pageNo:\n",
    "       the page to be scraped\n",
    "   -------\n",
    "   Returns a DataFrame of players\n",
    "   \"\"\"\n",
    "    #Get the URL\n",
    "    request = requests.get('https://www.futwiz.com/en/fifa22/players?page='+str(pageNo))\n",
    "    #Convert the site into HTML\n",
    "    soup = bs4.BeautifulSoup(request.text,'html5lib')\n",
    "    #Begin converting HTML into data\n",
    "    #Find all player names on a given page\n",
    "    name = soup.find_all('div', class_ = \"card-22-pack-name\")\n",
    "    #Use list comprehension to get a cleaned list of player names\n",
    "    names = [fix_names(clean_names(n.text),pageNo) for n in name]\n",
    "    #Repeat the process to find ratings, positions, and all the face card stats\n",
    "    rate = soup.find_all('div', class_ = \"card-22-pack-rating\")\n",
    "    ratings = [int(r.text) for r in rate]\n",
    "    pos = soup.find_all('div', class_ = \"card-22-pack-position\")\n",
    "    positions = [p.text for p in pos]\n",
    "    pac = soup.find_all('div', class_ = \"card-22-pack-attnum1\")\n",
    "    pace = [int(p.text) for p in pac]\n",
    "    shot = soup.find_all('div', class_ = \"card-22-pack-attnum2\")\n",
    "    shooting = [int(s.text) for s in shot]\n",
    "    pas = soup.find_all('div', class_ = \"card-22-pack-attnum3\")\n",
    "    passing = [p.text for p in pas]\n",
    "    dri = soup.find_all('div', class_ = \"card-22-pack-attnum4\")\n",
    "    dribbling = [int(d.text) for d in dri]\n",
    "    defend = soup.find_all('div', class_ = \"card-22-pack-attnum5\")\n",
    "    defending = [int(d.text) for d in defend]\n",
    "    phys = soup.find_all('div', class_ = \"card-22-pack-attnum6\")\n",
    "    physical = [p.text for p in phys]\n",
    "    #For non face card stats such as skill moves and work rates, more cleaning work is needed.\n",
    "    #First get all non face card stats for each player and convert it to a list called attrs.\n",
    "    tags = soup.find_all('div', class_ = \"latest-player-info-stat\")\n",
    "    attrs = [a.text for a in tags]\n",
    "    #Next we group our list into lists of all 4 non face card stats \n",
    "    attribs = [attrs[i:i + 4] for i in range(0, len(attrs), 4)]\n",
    "    #Now go through each group to define lists of the four non face card stats\n",
    "    skills = [int(attrib[0]) for attrib in attribs]\n",
    "    wf = [int(attrib[1]) for attrib in attribs]\n",
    "    wr = [attrib[2] for attrib in attribs]\n",
    "    foot = [attrib[3] for attrib in attribs]\n",
    "    #Repeat the previous process to get a cleaned list of players price\n",
    "    pri = soup.find_all('div', class_ = \"latest-player-info-price\")\n",
    "    price = [clean_price(p.text) for p in pri]\n",
    "    #Define an array of all the scraped lists\n",
    "    dat = {'Player':names,'Rating':ratings,'Position':positions,'Pace':pace,'Shooting':shooting,'Passing':passing,'Dribbling':dribbling,'Defending':defending,'Physical':physical,'Skills':skills,'Weak_Foot':wf,'Work_Rates':wr,'Foot':foot,'Price':price}\n",
    "    #Convert the array into a DataFrame\n",
    "    data = pd.DataFrame(dat)\n",
    "    #Clean the dataframe slightly and return it\n",
    "    data.index = data.Player\n",
    "    data.pop('Player')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafdb933",
   "metadata": {},
   "source": [
    "Now that we have a method of collecting data from one page on the site, let's define a function to that scrapes data from multiple pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea7a5230",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_more(low, high):\n",
    "    \"\"\"\n",
    "   A function that scrapes a given page range on Futwiz and gives us data to work with\n",
    "   \n",
    "   Parameters\n",
    "   ----------\n",
    "   low:\n",
    "       the first page number to scrape\n",
    "   high:\n",
    "       the last page number to scrape\n",
    "   -------\n",
    "   Returns a DataFrame of players\n",
    "   \"\"\"\n",
    "    #Start with the first page\n",
    "    data = get_data(low)\n",
    "    #Loop until the last page and append each new dataframe to the first one\n",
    "    for i in range(low+1,high):\n",
    "        dat = get_data(i)\n",
    "        data = data.append(dat)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da0bdc2",
   "metadata": {},
   "source": [
    "Now we have a completed methodology of scraping and obtaining data. Code to obtain the data and export it as a csv is commented out and included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4083b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data on pages 1-3\n",
    "# data = data.get_more(0,3)\n",
    "# Export as csv\n",
    "# data.to_csv('filename')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
